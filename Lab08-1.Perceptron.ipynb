{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x252d2d1a2b0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F \r\n",
    "import torch.optim as optim \r\n",
    "\r\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "torch.manual_seed(777)\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], \r\n",
    "                       [0, 1], \r\n",
    "                       [1, 0], \r\n",
    "                       [1, 1]]).to(device)\r\n",
    "Y = torch.FloatTensor([[0], \r\n",
    "                       [1], \r\n",
    "                       [1], \r\n",
    "                       [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(2, 1, bias=True)\r\n",
    "sigmoid = nn.Sigmoid()\r\n",
    "model = nn.Sequential(linear, sigmoid).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수와 옵티마이저 정의\r\n",
    "criterion = torch.nn.BCELoss().to(device)\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:      0/10,000, COST:   0.727397\n",
      "STEP:    100/10,000, COST:   0.693148\n",
      "STEP:    200/10,000, COST:   0.693147\n",
      "STEP:    300/10,000, COST:   0.693147\n",
      "STEP:    400/10,000, COST:   0.693147\n",
      "STEP:    500/10,000, COST:   0.693147\n",
      "STEP:    600/10,000, COST:   0.693147\n",
      "STEP:    700/10,000, COST:   0.693147\n",
      "STEP:    800/10,000, COST:   0.693147\n",
      "STEP:    900/10,000, COST:   0.693147\n",
      "STEP:  1,000/10,000, COST:   0.693147\n",
      "STEP:  1,100/10,000, COST:   0.693147\n",
      "STEP:  1,200/10,000, COST:   0.693147\n",
      "STEP:  1,300/10,000, COST:   0.693147\n",
      "STEP:  1,400/10,000, COST:   0.693147\n",
      "STEP:  1,500/10,000, COST:   0.693147\n",
      "STEP:  1,600/10,000, COST:   0.693147\n",
      "STEP:  1,700/10,000, COST:   0.693147\n",
      "STEP:  1,800/10,000, COST:   0.693147\n",
      "STEP:  1,900/10,000, COST:   0.693147\n",
      "STEP:  2,000/10,000, COST:   0.693147\n",
      "STEP:  2,100/10,000, COST:   0.693147\n",
      "STEP:  2,200/10,000, COST:   0.693147\n",
      "STEP:  2,300/10,000, COST:   0.693147\n",
      "STEP:  2,400/10,000, COST:   0.693147\n",
      "STEP:  2,500/10,000, COST:   0.693147\n",
      "STEP:  2,600/10,000, COST:   0.693147\n",
      "STEP:  2,700/10,000, COST:   0.693147\n",
      "STEP:  2,800/10,000, COST:   0.693147\n",
      "STEP:  2,900/10,000, COST:   0.693147\n",
      "STEP:  3,000/10,000, COST:   0.693147\n",
      "STEP:  3,100/10,000, COST:   0.693147\n",
      "STEP:  3,200/10,000, COST:   0.693147\n",
      "STEP:  3,300/10,000, COST:   0.693147\n",
      "STEP:  3,400/10,000, COST:   0.693147\n",
      "STEP:  3,500/10,000, COST:   0.693147\n",
      "STEP:  3,600/10,000, COST:   0.693147\n",
      "STEP:  3,700/10,000, COST:   0.693147\n",
      "STEP:  3,800/10,000, COST:   0.693147\n",
      "STEP:  3,900/10,000, COST:   0.693147\n",
      "STEP:  4,000/10,000, COST:   0.693147\n",
      "STEP:  4,100/10,000, COST:   0.693147\n",
      "STEP:  4,200/10,000, COST:   0.693147\n",
      "STEP:  4,300/10,000, COST:   0.693147\n",
      "STEP:  4,400/10,000, COST:   0.693147\n",
      "STEP:  4,500/10,000, COST:   0.693147\n",
      "STEP:  4,600/10,000, COST:   0.693147\n",
      "STEP:  4,700/10,000, COST:   0.693147\n",
      "STEP:  4,800/10,000, COST:   0.693147\n",
      "STEP:  4,900/10,000, COST:   0.693147\n",
      "STEP:  5,000/10,000, COST:   0.693147\n",
      "STEP:  5,100/10,000, COST:   0.693147\n",
      "STEP:  5,200/10,000, COST:   0.693147\n",
      "STEP:  5,300/10,000, COST:   0.693147\n",
      "STEP:  5,400/10,000, COST:   0.693147\n",
      "STEP:  5,500/10,000, COST:   0.693147\n",
      "STEP:  5,600/10,000, COST:   0.693147\n",
      "STEP:  5,700/10,000, COST:   0.693147\n",
      "STEP:  5,800/10,000, COST:   0.693147\n",
      "STEP:  5,900/10,000, COST:   0.693147\n",
      "STEP:  6,000/10,000, COST:   0.693147\n",
      "STEP:  6,100/10,000, COST:   0.693147\n",
      "STEP:  6,200/10,000, COST:   0.693147\n",
      "STEP:  6,300/10,000, COST:   0.693147\n",
      "STEP:  6,400/10,000, COST:   0.693147\n",
      "STEP:  6,500/10,000, COST:   0.693147\n",
      "STEP:  6,600/10,000, COST:   0.693147\n",
      "STEP:  6,700/10,000, COST:   0.693147\n",
      "STEP:  6,800/10,000, COST:   0.693147\n",
      "STEP:  6,900/10,000, COST:   0.693147\n",
      "STEP:  7,000/10,000, COST:   0.693147\n",
      "STEP:  7,100/10,000, COST:   0.693147\n",
      "STEP:  7,200/10,000, COST:   0.693147\n",
      "STEP:  7,300/10,000, COST:   0.693147\n",
      "STEP:  7,400/10,000, COST:   0.693147\n",
      "STEP:  7,500/10,000, COST:   0.693147\n",
      "STEP:  7,600/10,000, COST:   0.693147\n",
      "STEP:  7,700/10,000, COST:   0.693147\n",
      "STEP:  7,800/10,000, COST:   0.693147\n",
      "STEP:  7,900/10,000, COST:   0.693147\n",
      "STEP:  8,000/10,000, COST:   0.693147\n",
      "STEP:  8,100/10,000, COST:   0.693147\n",
      "STEP:  8,200/10,000, COST:   0.693147\n",
      "STEP:  8,300/10,000, COST:   0.693147\n",
      "STEP:  8,400/10,000, COST:   0.693147\n",
      "STEP:  8,500/10,000, COST:   0.693147\n",
      "STEP:  8,600/10,000, COST:   0.693147\n",
      "STEP:  8,700/10,000, COST:   0.693147\n",
      "STEP:  8,800/10,000, COST:   0.693147\n",
      "STEP:  8,900/10,000, COST:   0.693147\n",
      "STEP:  9,000/10,000, COST:   0.693147\n",
      "STEP:  9,100/10,000, COST:   0.693147\n",
      "STEP:  9,200/10,000, COST:   0.693147\n",
      "STEP:  9,300/10,000, COST:   0.693147\n",
      "STEP:  9,400/10,000, COST:   0.693147\n",
      "STEP:  9,500/10,000, COST:   0.693147\n",
      "STEP:  9,600/10,000, COST:   0.693147\n",
      "STEP:  9,700/10,000, COST:   0.693147\n",
      "STEP:  9,800/10,000, COST:   0.693147\n",
      "STEP:  9,900/10,000, COST:   0.693147\n",
      "STEP: 10,000/10,000, COST:   0.693147\n"
     ]
    }
   ],
   "source": [
    "#10,001번의 에포크 수행. 0번 에포크부터 10,000번 에포크까지.\r\n",
    "for step in range(10001): \r\n",
    "    optimizer.zero_grad()\r\n",
    "    hypothesis = model(X)\r\n",
    "\r\n",
    "    # 비용 함수\r\n",
    "    cost = criterion(hypothesis, Y)\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if step % 100 == 0: # 100번째 에포크마다 비용 출력\r\n",
    "        print(f\"STEP: {step:>6,}/10,000, COST: {cost.item():>10.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):\n",
      "[[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "\n",
      "\n",
      "모델의 예측값(Predicted):\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "\n",
      "실제값(Y):\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "\n",
      "정확도(Accuracy): 50.0000%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\r\n",
    "    hypothesis = model(X)\r\n",
    "    predicted = (hypothesis > 0.5).float()\r\n",
    "    accuracy = (predicted == Y).float().mean()\r\n",
    "    print(f'모델의 출력값(Hypothesis):\\n{hypothesis.detach().cpu().numpy()}\\n\\n')\r\n",
    "    print(f'모델의 예측값(Predicted):\\n{predicted.detach().cpu().numpy()}\\n\\n')\r\n",
    "    print(f'실제값(Y):\\n{Y.cpu().numpy()}\\n')\r\n",
    "    print(f'정확도(Accuracy): {accuracy.item()*100:.4f}%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('PyTorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "10ab15d463b6da8d8043090fbca014f3f73faff96cb051ed518ae7cbb88f5f23"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}