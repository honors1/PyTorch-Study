{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x21584b7a2b0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F \r\n",
    "import torch.optim as optim \r\n",
    "\r\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "# for reproducibility\r\n",
    "torch.manual_seed(777)\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], \r\n",
    "                       [0, 1], \r\n",
    "                       [1, 0], \r\n",
    "                       [1, 1]]).to(device)\r\n",
    "Y = torch.FloatTensor([[0], \r\n",
    "                       [1], \r\n",
    "                       [1], \r\n",
    "                       [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\r\n",
    "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\r\n",
    "          nn.Sigmoid(),\r\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\r\n",
    "          nn.Sigmoid(),\r\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\r\n",
    "          nn.Sigmoid(),\r\n",
    "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\r\n",
    "          nn.Sigmoid()\r\n",
    "          ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss().to(device)\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:      0/10,000, COST:   0.693158\n",
      "epoch:    100/10,000, COST:   0.693156\n",
      "epoch:    200/10,000, COST:   0.693154\n",
      "epoch:    300/10,000, COST:   0.693151\n",
      "epoch:    400/10,000, COST:   0.693149\n",
      "epoch:    500/10,000, COST:   0.693147\n",
      "epoch:    600/10,000, COST:   0.693145\n",
      "epoch:    700/10,000, COST:   0.693143\n",
      "epoch:    800/10,000, COST:   0.693142\n",
      "epoch:    900/10,000, COST:   0.693140\n",
      "epoch:  1,000/10,000, COST:   0.693138\n",
      "epoch:  1,100/10,000, COST:   0.693136\n",
      "epoch:  1,200/10,000, COST:   0.693134\n",
      "epoch:  1,300/10,000, COST:   0.693132\n",
      "epoch:  1,400/10,000, COST:   0.693130\n",
      "epoch:  1,500/10,000, COST:   0.693128\n",
      "epoch:  1,600/10,000, COST:   0.693126\n",
      "epoch:  1,700/10,000, COST:   0.693124\n",
      "epoch:  1,800/10,000, COST:   0.693122\n",
      "epoch:  1,900/10,000, COST:   0.693120\n",
      "epoch:  2,000/10,000, COST:   0.693117\n",
      "epoch:  2,100/10,000, COST:   0.693114\n",
      "epoch:  2,200/10,000, COST:   0.693112\n",
      "epoch:  2,300/10,000, COST:   0.693108\n",
      "epoch:  2,400/10,000, COST:   0.693105\n",
      "epoch:  2,500/10,000, COST:   0.693101\n",
      "epoch:  2,600/10,000, COST:   0.693097\n",
      "epoch:  2,700/10,000, COST:   0.693093\n",
      "epoch:  2,800/10,000, COST:   0.693088\n",
      "epoch:  2,900/10,000, COST:   0.693082\n",
      "epoch:  3,000/10,000, COST:   0.693076\n",
      "epoch:  3,100/10,000, COST:   0.693069\n",
      "epoch:  3,200/10,000, COST:   0.693061\n",
      "epoch:  3,300/10,000, COST:   0.693052\n",
      "epoch:  3,400/10,000, COST:   0.693041\n",
      "epoch:  3,500/10,000, COST:   0.693028\n",
      "epoch:  3,600/10,000, COST:   0.693013\n",
      "epoch:  3,700/10,000, COST:   0.692995\n",
      "epoch:  3,800/10,000, COST:   0.692972\n",
      "epoch:  3,900/10,000, COST:   0.692945\n",
      "epoch:  4,000/10,000, COST:   0.692909\n",
      "epoch:  4,100/10,000, COST:   0.692864\n",
      "epoch:  4,200/10,000, COST:   0.692803\n",
      "epoch:  4,300/10,000, COST:   0.692720\n",
      "epoch:  4,400/10,000, COST:   0.692601\n",
      "epoch:  4,500/10,000, COST:   0.692423\n",
      "epoch:  4,600/10,000, COST:   0.692141\n",
      "epoch:  4,700/10,000, COST:   0.691654\n",
      "epoch:  4,800/10,000, COST:   0.690713\n",
      "epoch:  4,900/10,000, COST:   0.688553\n",
      "epoch:  5,000/10,000, COST:   0.681835\n",
      "epoch:  5,100/10,000, COST:   0.645616\n",
      "epoch:  5,200/10,000, COST:   0.534673\n",
      "epoch:  5,300/10,000, COST:   0.039789\n",
      "epoch:  5,400/10,000, COST:   0.009608\n",
      "epoch:  5,500/10,000, COST:   0.004996\n",
      "epoch:  5,600/10,000, COST:   0.003279\n",
      "epoch:  5,700/10,000, COST:   0.002406\n",
      "epoch:  5,800/10,000, COST:   0.001886\n",
      "epoch:  5,900/10,000, COST:   0.001542\n",
      "epoch:  6,000/10,000, COST:   0.001300\n",
      "epoch:  6,100/10,000, COST:   0.001121\n",
      "epoch:  6,200/10,000, COST:   0.000983\n",
      "epoch:  6,300/10,000, COST:   0.000874\n",
      "epoch:  6,400/10,000, COST:   0.000786\n",
      "epoch:  6,500/10,000, COST:   0.000713\n",
      "epoch:  6,600/10,000, COST:   0.000652\n",
      "epoch:  6,700/10,000, COST:   0.000600\n",
      "epoch:  6,800/10,000, COST:   0.000556\n",
      "epoch:  6,900/10,000, COST:   0.000517\n",
      "epoch:  7,000/10,000, COST:   0.000483\n",
      "epoch:  7,100/10,000, COST:   0.000454\n",
      "epoch:  7,200/10,000, COST:   0.000427\n",
      "epoch:  7,300/10,000, COST:   0.000403\n",
      "epoch:  7,400/10,000, COST:   0.000382\n",
      "epoch:  7,500/10,000, COST:   0.000363\n",
      "epoch:  7,600/10,000, COST:   0.000345\n",
      "epoch:  7,700/10,000, COST:   0.000329\n",
      "epoch:  7,800/10,000, COST:   0.000315\n",
      "epoch:  7,900/10,000, COST:   0.000301\n",
      "epoch:  8,000/10,000, COST:   0.000289\n",
      "epoch:  8,100/10,000, COST:   0.000278\n",
      "epoch:  8,200/10,000, COST:   0.000267\n",
      "epoch:  8,300/10,000, COST:   0.000257\n",
      "epoch:  8,400/10,000, COST:   0.000248\n",
      "epoch:  8,500/10,000, COST:   0.000239\n",
      "epoch:  8,600/10,000, COST:   0.000231\n",
      "epoch:  8,700/10,000, COST:   0.000224\n",
      "epoch:  8,800/10,000, COST:   0.000217\n",
      "epoch:  8,900/10,000, COST:   0.000210\n",
      "epoch:  9,000/10,000, COST:   0.000204\n",
      "epoch:  9,100/10,000, COST:   0.000198\n",
      "epoch:  9,200/10,000, COST:   0.000192\n",
      "epoch:  9,300/10,000, COST:   0.000187\n",
      "epoch:  9,400/10,000, COST:   0.000182\n",
      "epoch:  9,500/10,000, COST:   0.000177\n",
      "epoch:  9,600/10,000, COST:   0.000173\n",
      "epoch:  9,700/10,000, COST:   0.000168\n",
      "epoch:  9,800/10,000, COST:   0.000164\n",
      "epoch:  9,900/10,000, COST:   0.000160\n",
      "epoch: 10,000/10,000, COST:   0.000157\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10001):\r\n",
    "    optimizer.zero_grad()\r\n",
    "    # forward 연산\r\n",
    "    hypothesis = model(X)\r\n",
    "\r\n",
    "    # 비용 함수\r\n",
    "    cost = criterion(hypothesis, Y)\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    # 100의 배수에 해당되는 에포크마다 비용을 출력\r\n",
    "    if epoch % 100 == 0:\r\n",
    "        print(f\"epoch: {epoch:>6,}/10,000, COST: {cost.item():>10.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):\n",
      "[[1.1169377e-04]\n",
      " [9.9982882e-01]\n",
      " [9.9984229e-01]\n",
      " [1.8525735e-04]]\n",
      "\n",
      "\n",
      "모델의 예측값(Predicted):\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "\n",
      "\n",
      "실제값(Y):\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "\n",
      "정확도(Accuracy): 100.0000%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\r\n",
    "    hypothesis = model(X)\r\n",
    "    predicted = (hypothesis > 0.5).float()\r\n",
    "    accuracy = (predicted == Y).float().mean()\r\n",
    "    print(f'모델의 출력값(Hypothesis):\\n{hypothesis.detach().cpu().numpy()}\\n\\n')\r\n",
    "    print(f'모델의 예측값(Predicted):\\n{predicted.detach().cpu().numpy()}\\n\\n')\r\n",
    "    print(f'실제값(Y):\\n{Y.cpu().numpy()}\\n')\r\n",
    "    print(f'정확도(Accuracy): {accuracy.item()*100:.4f}%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('PyTorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "10ab15d463b6da8d8043090fbca014f3f73faff96cb051ed518ae7cbb88f5f23"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}